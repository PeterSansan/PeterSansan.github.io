<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>所有人都能学会用Python写出RNN代码 | blog of PeterSansan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="英文原文：Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) 中文原文：所有人都能学会用Python写出RNN-LSTM代码 【说明】：我在原文中简化了一些解释，因为感觉不是很必要，并且也加了一点自己的理解，我看了代码，其实并不相信这个代码与LSTM有关系，这个代码应该只中RNN，并没有LSTM 第一部分：什么是神经元记忆神经">
<meta name="keywords" content="LSTM,深度学习">
<meta property="og:type" content="article">
<meta property="og:title" content="所有人都能学会用Python写出RNN代码">
<meta property="og:url" content="http://petersansan.top/2017/04/25/所有人都能学会用Python写出RNN-LSTM代码/index.html">
<meta property="og:site_name" content="blog of PeterSansan">
<meta property="og:description" content="英文原文：Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) 中文原文：所有人都能学会用Python写出RNN-LSTM代码 【说明】：我在原文中简化了一些解释，因为感觉不是很必要，并且也加了一点自己的理解，我看了代码，其实并不相信这个代码与LSTM有关系，这个代码应该只中RNN，并没有LSTM 第一部分：什么是神经元记忆神经">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/xxd.png?imageslim">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/rn1.png?imageslim">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/rn2.png?imageslim">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/rnn3.png?imageView2/2/h/300">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/recurrence_gif.gif?imageView2/2/h/400">
<meta property="og:image" content="http://ogtxggxo6.bkt.clouddn.com/backprop_through_time.gif?imageView2/2/h/400">
<meta property="og:updated_time" content="2017-04-25T15:01:07.074Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="所有人都能学会用Python写出RNN代码">
<meta name="twitter:description" content="英文原文：Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN) 中文原文：所有人都能学会用Python写出RNN-LSTM代码 【说明】：我在原文中简化了一些解释，因为感觉不是很必要，并且也加了一点自己的理解，我看了代码，其实并不相信这个代码与LSTM有关系，这个代码应该只中RNN，并没有LSTM 第一部分：什么是神经元记忆神经">
<meta name="twitter:image" content="http://ogtxggxo6.bkt.clouddn.com/xxd.png?imageslim">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">blog of PeterSansan</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Just Do It.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
          <a class="main-nav-link" href="/other">Other</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://petersansan.top"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-所有人都能学会用Python写出RNN-LSTM代码" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/04/25/所有人都能学会用Python写出RNN-LSTM代码/" class="article-date">
  <time datetime="2017-04-24T17:00:29.000Z" itemprop="datePublished">2017-04-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      所有人都能学会用Python写出RNN代码
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://ogtxggxo6.bkt.clouddn.com/xxd.png?imageslim" alt=""></p>
<p>英文原文：<a href="http://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/" target="_blank" rel="external">Anyone Can Learn To Code an LSTM-RNN in Python (Part 1: RNN)</a></p>
<p>中文原文：<a href="http://magicly.me/2017/03/09/iamtrask-anyone-can-code-lstm/?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="external">所有人都能学会用Python写出RNN-LSTM代码</a></p>
<p>【说明】：我在原文中简化了一些解释，因为感觉不是很必要，并且也加了一点自己的理解，我看了代码，其实并不相信这个代码与LSTM有关系，这个代码应该只中RNN，并没有LSTM</p>
<h2 id="第一部分：什么是神经元记忆"><a href="#第一部分：什么是神经元记忆" class="headerlink" title="第一部分：什么是神经元记忆"></a>第一部分：什么是神经元记忆</h2><p>神经网络有隐藏层。一般而言，隐藏层的状态由输入决定。所以，一般而言神经网络的信息流如下图：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">input -&gt; hidden -&gt; output</div></pre></td></tr></table></figure>
<p>这很简单直接。特定的输入决定特定的隐藏层，特定的隐藏层又决定了输出。这是一种封闭系统。记忆改变了这种状况。记忆意味着，隐藏状态是由当前时间点的输入和上一个时间点的隐藏状态决定的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(input + prev_hidden) -&gt; hidden -&gt; output</div></pre></td></tr></table></figure>
<p>为什么是隐藏层而不是输入层呢？我们也可以这样做呀：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(input + prev_input) -&gt; hidden -&gt; output</div></pre></td></tr></table></figure>
<p>现在，仔细想想，如果有四个时间点，如果我们采用隐藏层循环是如下图：</p>
<p><img src="http://ogtxggxo6.bkt.clouddn.com/rn1.png?imageslim" alt=""></p>
<p><img src="http://ogtxggxo6.bkt.clouddn.com/rn2.png?imageslim" alt=""></p>
<p>看到区别没，隐藏层记忆了之前所有的输入信息，而输入层循环则只能利用到上一个输入。</p>
<p>举个例子，假设一首歌词里面有”….I love you…”和”…I love carrots…”，如果采用输入层循环，则没法根据”I love”来预测下一个词是什么？因为当前输入是love，前一个输入是I，这两种情况一致，所以没法区分。 而隐藏层循环则可以记住更久之前的输入信息，因而能更好地预测下一个词。理论上而言，隐藏层循环可以记住所有之前的输入，当然记忆会随着时间流逝逐渐忘却。有兴趣的可以看<strong><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">这篇blog</a></strong>。</p>
<h2 id="第二部分：RNN-神经网络记忆"><a href="#第二部分：RNN-神经网络记忆" class="headerlink" title="第二部分：RNN - 神经网络记忆"></a>第二部分：RNN - 神经网络记忆</h2><p>现在我们已经有了一些直观认识， 接下来让我们更进一步分析。正如在<a href="http://iamtrask.github.io/2015/07/12/basic-python-network/" target="_blank" rel="external">反向传播这篇blog</a>里介绍的，神经网络的输入层是由输入数据集决定的。每一行输入数据用来产生隐藏层（通过正向传播）。每个隐藏层又用于产生输出层（假设只有一层隐藏层）。如我们之前所说，记忆意味着隐藏层是由输入数据和前一次的隐藏层组合而成。怎么做的呢？很像神经网络里面其他传播的做法一样， 通过矩阵！这个矩阵定义了当前隐藏层跟前一个隐藏层的关系。</p>
<p><img src="http://ogtxggxo6.bkt.clouddn.com/rnn3.png?imageView2/2/h/300" alt=""></p>
<p>这幅图中很重要的一点是有三个权重矩阵。有两个我们很熟悉了。<code>SYNAPSE_0</code>用于把输入数据传播到隐藏层。<code>SYNAPSE_1</code>把隐藏层传播到输出数据。新矩阵（<code>SYNAPSE_h</code>，用于循环）把当前的隐藏层（<code>layer_1</code>）传播到下一个时间点的隐藏层（还是<code>layer_1</code>）。</p>
<p><img src="http://ogtxggxo6.bkt.clouddn.com/recurrence_gif.gif?imageView2/2/h/400" alt=""></p>
<p>上面的gif图展示了循环神经网络的神奇之处以及一些很重要的性质。它展示了四个时间点隐藏层的情况。第一个时间点，隐藏层仅由输入数据决定。第二个时间点，隐藏层是由输入数据和第一个时间点的隐藏层共同决定的。以此类推。你应该注意到了，第四个时间点的时候，网络已经“满了”。所以大概第五个时间点来的时候，就要选择哪些记忆保留，哪些记忆覆盖。现实如此。这就是记忆“容量”的概念。如你所想，更大的隐藏层，就能记住更长时间的东西。同样，这就需要神经网络学会<strong>忘记不相关的记忆</strong>然后<strong>记住重要的记忆</strong>。第三步有没看出什么重要信息？为什么<strong>绿色</strong>的要比其他颜色的多呢？</p>
<p>另外要注意的是隐藏层夹在输入层和输出层中间，所以输出已经不仅仅取决于输入了。输入仅仅改变记忆，而输出仅仅依赖于记忆。有趣的是，如果2，3，4时间节点没有输入数据的话，隐藏层同样会随着时间流逝而变化。</p>
<h2 id="第三部分：基于时间的反向传播"><a href="#第三部分：基于时间的反向传播" class="headerlink" title="第三部分：基于时间的反向传播"></a>第三部分：基于时间的反向传播</h2><p>那么循环神经网络是怎么学习的呢？看看下面的图。黑色表示预测结果，明黄色表示错误，褐黄色表示导数</p>
<p><img src="http://ogtxggxo6.bkt.clouddn.com/backprop_through_time.gif?imageView2/2/h/400" alt=""></p>
<p>网络通过从1到4的全部前向传播（可以是任意长度的整个序列），然后再从4到1的反向传播导数来学习。你可以把它看成一个有点变形的普通神经网络，除了我们在不同的地方的时间上<strong>共享权值</strong>（<code>synapses 0,1,and h</code>），这一点很重要。除了这点， 它就是一个普通的神经网络。这里我的理解是：LSTM代码中常使用的<code>timestep</code>即为这里的每隔4秒的意思</p>
<h2 id="第四部分：代码解析"><a href="#第四部分：代码解析" class="headerlink" title="第四部分：代码解析"></a>第四部分：代码解析</h2><p>代码地址看这里：<a href="">code</a></p>
<p>这个代码并不是实现了LSTM，而是RNN，因为它并没有遗忘门等结构。</p>
<p>代码包含如下内容：</p>
<ul>
<li><p>1）定义了sigmoid函数与sigmoid函数的导数</p>
</li>
<li><p>2）生成0~255的整形与二进制数据</p>
</li>
<li><p>3）初始化参数</p>
</li>
<li><p>4）迭代10000次训练：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">for(timestep)</div><div class="line">&#123;</div><div class="line">    正向传播：</div><div class="line">    每次输入两个位，预测结果，计算错误率，叠加到总错误率，并存储每个时间点的误差导数，和每个时间点的隐藏层值</div><div class="line">&#125;</div><div class="line">for(timestep)</div><div class="line">&#123;</div><div class="line">    反向传播：</div><div class="line">    每个时间点的输出层误差导数</div><div class="line">    计算每个时间点的隐藏层误差导数</div><div class="line">    存储累加更新矩阵</div><div class="line">&#125;</div><div class="line">更新参数</div><div class="line">每1000个数据输出结果；</div></pre></td></tr></table></figure>
</li>
</ul>
<p>备注：感觉自己的反向传播权值更新是难点，原作并没有讲得很清楚，我也还没理解，这部门待后述补充。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://petersansan.top/2017/04/25/所有人都能学会用Python写出RNN-LSTM代码/" data-id="cj1xojaim000hllif0432d29d" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LSTM/">LSTM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>

    </footer>
	
    <div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
    <script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script>
    <script>
    var cloudTieConfig = {
      url: document.location.href, 
      sourceId: "",
      productKey: "e2a8be6e9b7f4bf7aa3c3f956be2ce37",
      target: "cloud-tie-wrapper"
    };
    var yunManualLoad = true;
    Tie.loader("aHR0cHM6Ly9hcGkuZ2VudGllLjE2My5jb20vcGMvbGl2ZXNjcmlwdC5odG1s", true);
    </script>
	
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/04/24/LSTM神经网络输入输出究竟是怎样的/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          LSTM神经网络输入输出究竟是怎样的?
        
      </div>
    </a>
  
  
    <a href="/2017/04/25/人生管理/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">人生管理</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/序列标注/">序列标注</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/有感/">有感</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/服务器/">服务器</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/资源/">资源</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/github/" style="font-size: 15px;">github</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/nlp/" style="font-size: 10px;">nlp</a> <a href="/tags/ubuntu/" style="font-size: 10px;">ubuntu</a> <a href="/tags/webapp/" style="font-size: 10px;">webapp</a> <a href="/tags/中文分词/" style="font-size: 10px;">中文分词</a> <a href="/tags/价值观/" style="font-size: 10px;">价值观</a> <a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/序列标注/" style="font-size: 15px;">序列标注</a> <a href="/tags/服务器/" style="font-size: 10px;">服务器</a> <a href="/tags/概率图模型/" style="font-size: 10px;">概率图模型</a> <a href="/tags/深度学习/" style="font-size: 20px;">深度学习</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/综述/" style="font-size: 10px;">综述</a> <a href="/tags/转载/" style="font-size: 10px;">转载</a> <a href="/tags/递归/" style="font-size: 10px;">递归</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/">LSTM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/">nlp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ubuntu/">ubuntu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/webapp/">webapp</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/中文分词/">中文分词</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/价值观/">价值观</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工具/">工具</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/序列标注/">序列标注</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/服务器/">服务器</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/概率图模型/">概率图模型</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/综述/">综述</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/转载/">转载</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/递归/">递归</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">四月 2017</a><span class="archive-list-count">17</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/04/25/人生管理/">人生管理</a>
          </li>
        
          <li>
            <a href="/2017/04/25/所有人都能学会用Python写出RNN-LSTM代码/">所有人都能学会用Python写出RNN代码</a>
          </li>
        
          <li>
            <a href="/2017/04/24/LSTM神经网络输入输出究竟是怎样的/">LSTM神经网络输入输出究竟是怎样的?</a>
          </li>
        
          <li>
            <a href="/2017/04/22/jupyter主题安装/">jupyter主题安装</a>
          </li>
        
          <li>
            <a href="/2017/04/22/git若干操作/">git若干操作</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 PeterSansan<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/other" class="mobile-nav-link">Other</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>